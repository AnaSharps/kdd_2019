\documentclass[11pt,
			   %10pt, 
               %hyperref={colorlinks},
               aspectratio=169,
               hyperref={colorlinks}
               ]{beamer}
\usetheme{Singapore}
\usecolortheme[snowy, cautious]{owl}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[american]{babel}
\usepackage{graphicx}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    urlcolor=[rgb]{1,0,1},
    linkcolor=[rgb]{1,0,1}}
\definecolor{magenta}{RGB}{255, 0, 255}

\usepackage[natbib=true,style=numeric,backend=bibtex,useprefix=true]{biblatex}

\definecolor{OwlGreen}{RGB}{75,0,130} % easier to see
\setbeamertemplate{bibliography item}{\insertbiblabel}
\setbeamerfont{caption}{size=\footnotesize}
\setbeamertemplate{frametitle continuation}{}

\setcounter{tocdepth}{1}
\renewcommand*{\bibfont}{\scriptsize}
\addbibresource{bibliography.bib}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

\usenavigationsymbolstemplate{}
\setbeamertemplate{footline}{%
    \raisebox{5pt}{\makebox{\hfill\makebox[20pt]{\color{gray}
          \scriptsize\insertframenumber}}}\hspace*{5pt}}

\author{\copyright\hspace{1pt}Patrick Hall\footnote{\tiny{This material is shared under a \href{https://creativecommons.org/licenses/by/4.0/deed.ast}{CC By 4.0 license} which allows for editing and redistribution, even for commercial purposes. However, any derivative work should attribute the author and H2O.ai.}}}
\title{Guidelines for Responsible Use of Explainable Machine Learning}
\logo{\includegraphics[height=8pt]{img/h2o_logo.png}}
\institute{\href{https://www.h2o.ai}{H\textsubscript{2}O.ai}}
\date{\today}
\subject{}

\begin{document}
	
	\maketitle
	
	\begin{frame}
	
		\frametitle{Contents}
		
		\tableofcontents{}
		
	\end{frame}

%-------------------------------------------------------------------------------
	\section{Introduction}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
	\subsection{What?}
%-------------------------------------------------------------------------------

% sameer defintion

	\begin{frame}[t]
		
		\frametitle{What is explainable machine learning (ML)?}
		
		Variously defined along with aliases or similar concepts:
		\vspace{5pt}
		\begin{itemize}\footnotesize
			\item ``Towards a Rigorous Science of Interpretable Machine Learning'' (\citet{been_kim1})
			\item ``Explaining Explanations'' (\citet{gilpin2018explaining})
			\item ``A Survey Of Methods For Explaining Black Box Models'' (\citet{guidotti2018survey})
			\item ``The Mythos of Model Interpretability'' (\citet{lipton1})
		 	\item \textit{Interpretable Machine Learning} (\citet{molnar})
			\item ``Interpretable Machine Learning: Definitions, Methods, and Applications'' (\citet{murdoch2019interpretable})
			\item ``Challenges for Transparency'' (\citet{weller2017challenges}). 
		\end{itemize}\normalsize
		
	\end{frame}
	
	\begin{frame}
	
		\frametitle{What is explainable ML?}

		What do \textit{\textbf{I}} mean by explainable ML?\\
		\vspace{5pt}
		Mostly post-hoc techniques used to enhance \textit{\textbf{understanding}} of trained model mechansims and predictions, e.g. ...
		\begin{itemize}
			\item \textbf{Direct measures of global and local feature importance}: 
			\begin{itemize}\footnotesize
				\item Gradient-based feature attribution (\citet{grad_attr})
				\item Shapley values (\citet{shapley})
			\end{itemize}
			\item \textbf{Global and local surrogate models}: 
			\begin{itemize}\footnotesize
				\item Decision tree variants (\citet{viper}, \citet{dt_surrogate1})
				\item Anchors (\citet{anchors})
				\item Local interpretable model-agnostic explanations (LIME) (\citet{lime})
			\end{itemize}
			\item \textbf{Global and local visualizations of trained model predictions}: 
			\begin{itemize}\footnotesize
				\item Accumulated local effect (ALE) (\citet{ale_plot}) 
				\item Partial dependence (\citet{esl})
				\item Individual conditional expectation (ICE) (\citet{ice_plots})
			\end{itemize}
		\end{itemize}\normalsize
			
	\end{frame}
	
%-------------------------------------------------------------------------------
	\subsection{Why?}
%-------------------------------------------------------------------------------

% ask for contributions to awesome-machine-learning-interpretability

	\begin{frame}
	
		\frametitle{Why explainable ML?}
		\vspace{10pt}
		Responsible Use of Explainable ML can enable:
		\begin{itemize}\footnotesize
			\item Human learning from machine learning
			\item Human appeal of automated decisions
			\item Regulatory compliance
			\item White-hat hacking
		\end{itemize}
		\vspace{5pt}
		Misuse and Abuse of Explainable ML can enable:
		\begin{itemize}\footnotesize
			\item Model and data stealing (\citet{model_stealing}, \citet{membership_inference}, \citet{shokri2019privacy})
			\item False justification for black-boxes, e.g. ``fairwashing'' (\citet{fair_washing}, \citet{please_stop})
		\end{itemize}
		\normalsize
		
	\end{frame}
	
%-------------------------------------------------------------------------------
	\subsection{Guidelines}
%-------------------------------------------------------------------------------	

	\begin{frame}
	
		\frametitle{Proposed Guidelines for Responsible Use}
		
		Explainable ML is already in-use: numerous open source\footnote{\tiny{See: \url{https://github.com/jphall663/awesome-machine-learning-interpretability}}} and commercial packages\footnote{\tiny{For instance  Datarobot, H2O Driverless AI, SAS Visual Data Mining and Machine Learning, Zest AutoML}} available today.\\
		\vspace{5pt}
		Best-practices are needed to prevent misuse and abuse. So, four basic guidelines are proposed here:
		\vspace{5pt}
		\begin{itemize}
			\item Use explainable ML to enhance understanding.
			\item Learn how explainable ML is used for nefarious purposes.
			\item Augment surrogate models with direct explanations.
			\item Use highly transparent mechanisms for high-stakes applications.
		\end{itemize}
		
	\end{frame}

%-------------------------------------------------------------------------------
	\section{Understanding and Trust}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
	\section{The Dark Side}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
	\section{Surrogates}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
	\section{High Stakes Applications}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
%	\section{References}
%-------------------------------------------------------------------------------

% which code for which slide

	\begin{frame}[t, allowframebreaks]
	
		\frametitle{References}	
		
			This presentation:\\
			\tiny{\url{https://www.github.com/jphall663kdd_2019}}\\
			\vspace{10pt}
			\normalsize Code examples for this presentation:\\
			\tiny{\url{https://www.github.com/jphall663/interpretable_machine_learning_with_python}}\\
			\noindent\tiny{\url{https://www.github.com/jphall663/responsible_xai}}\\
			\vspace{10pt}
			\normalsize Associated texts:\\
			\tiny{\url{https://arxiv.org/pdf/1810.02909.pdf}}\\
			\noindent\tiny{\url{https://arxiv.org/pdf/1906.03533.pdf}}
								
		\framebreak		
		
		\printbibliography
		
	\end{frame}

\end{document}